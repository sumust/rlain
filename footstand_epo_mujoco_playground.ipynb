{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumust/rlain/blob/main/footstand_epo_mujoco_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpkYHwCqk7W-"
      },
      "source": [
        "# Handstand with Go1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqo7pyX-n72M",
        "outputId": "f43f9438-1540-4b4f-cc13-8c47033b0eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mujoco\n",
            "  Downloading mujoco-3.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco) (1.12.2)\n",
            "Collecting glfw (from mujoco)\n",
            "  Downloading glfw-2.9.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mujoco) (2.0.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco) (3.1.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco) (4.14.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco) (3.23.0)\n",
            "Downloading mujoco-3.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m204.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.9.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/243.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.9.0 mujoco-3.3.3\n",
            "Collecting mujoco_mjx\n",
            "  Downloading mujoco_mjx-3.3.3-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco_mjx) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco_mjx) (1.12.2)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mujoco_mjx) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mujoco_mjx) (0.5.1)\n",
            "Requirement already satisfied: mujoco>=3.3.3.dev0 in /usr/local/lib/python3.11/dist-packages (from mujoco_mjx) (3.3.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mujoco_mjx) (1.15.3)\n",
            "Collecting trimesh (from mujoco_mjx)\n",
            "  Downloading trimesh-4.6.12-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.11/dist-packages (from mujoco>=3.3.3.dev0->mujoco_mjx) (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mujoco>=3.3.3.dev0->mujoco_mjx) (2.0.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco>=3.3.3.dev0->mujoco_mjx) (3.1.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco_mjx) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco_mjx) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco_mjx) (4.14.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco_mjx) (3.23.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mujoco_mjx) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mujoco_mjx) (3.4.0)\n",
            "Downloading mujoco_mjx-3.3.3-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.6.12-py3-none-any.whl (711 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m712.0/712.0 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh, mujoco_mjx\n",
            "Successfully installed mujoco_mjx-3.3.3 trimesh-4.6.12\n",
            "Collecting brax\n",
            "  Downloading brax-0.12.4-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from brax) (1.4.0)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.11/dist-packages (from brax) (1.12.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from brax) (3.1.1)\n",
            "Collecting flask-cors (from brax)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.11/dist-packages (from brax) (0.10.6)\n",
            "Requirement already satisfied: jax>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from brax) (0.5.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from brax) (0.5.1)\n",
            "Collecting jaxopt (from brax)\n",
            "  Downloading jaxopt-0.8.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from brax) (3.1.6)\n",
            "Collecting ml-collections (from brax)\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: mujoco in /usr/local/lib/python3.11/dist-packages (from brax) (3.3.3)\n",
            "Requirement already satisfied: mujoco-mjx in /usr/local/lib/python3.11/dist-packages (from brax) (3.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from brax) (2.0.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from brax) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from brax) (0.11.15)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from brax) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from brax) (1.15.3)\n",
            "Collecting tensorboardx (from brax)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (from brax) (4.6.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from brax) (4.14.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.6->brax) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.6->brax) (3.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax) (3.1.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax->brax) (1.1.1)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax->brax) (0.1.74)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax->brax) (13.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax->brax) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax->brax) (0.1.9)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.11/dist-packages (from mujoco->brax) (2.9.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco->brax) (3.1.9)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->brax) (0.1.89)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax) (3.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx->brax) (24.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->brax) (0.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->brax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->brax) (2.19.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->brax) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->brax) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->brax) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->brax) (0.1.2)\n",
            "Downloading brax-0.12.4-py3-none-any.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.7/341.7 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading jaxopt-0.8.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.4/172.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardx, ml-collections, flask-cors, jaxopt, brax\n",
            "Successfully installed brax-0.12.4 flask-cors-6.0.1 jaxopt-0.8.5 ml-collections-1.1.0 tensorboardx-2.6.4\n"
          ]
        }
      ],
      "source": [
        "#@title Install pre-requisites\n",
        "!pip install mujoco\n",
        "!pip install mujoco_mjx\n",
        "!pip install brax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbZxYDxzoz5R",
        "outputId": "692cf884-c3ae-41a3-e745-5911e1fdecbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting environment variable to use GPU rendering:\n",
            "env: MUJOCO_GL=egl\n",
            "Checking that the installation succeeded:\n",
            "Installation successful.\n"
          ]
        }
      ],
      "source": [
        "# @title Check if MuJoCo installation was successful\n",
        "\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.'\n",
        "  )\n",
        "\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".'\n",
        "  )\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags\n",
        "\n",
        "os.environ['MUJOCO_GL'] = 'egl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5f4w3Kq2X14",
        "outputId": "6d99734c-c470-426f-9e72-0398f17bb427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Import packages for plotting and creating graphics\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy\n",
        "import json\n",
        "import itertools\n",
        "import time\n",
        "from typing import Callable, List, NamedTuple, Optional, Union, Any, Dict, Sequence, Tuple # Added more types\n",
        "import numpy as np\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObF1UXrkb0Nd"
      },
      "outputs": [],
      "source": [
        "# @title Import MuJoCo, MJX, and Brax\n",
        "from datetime import datetime\n",
        "import functools\n",
        "\n",
        "from brax import base\n",
        "from brax import envs\n",
        "from brax import math\n",
        "from brax.base import Base, Motion, Transform\n",
        "from brax.base import State as PipelineState\n",
        "from brax.envs.base import Env, PipelineEnv, State as BraxState # Renamed to BraxState to avoid conflict if any\n",
        "from brax.io import html, mjcf, model\n",
        "from brax.mjx.base import State as MjxState\n",
        "from brax.training.agents.ppo import networks as ppo_networks\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.sac import networks as sac_networks\n",
        "from brax.training.agents.sac import train as sac\n",
        "from brax.envs.wrappers.training import AutoResetWrapper, VmapWrapper\n",
        "from etils import epath\n",
        "from flax import struct\n",
        "from flax.training import orbax_utils\n",
        "from IPython.display import HTML, clear_output\n",
        "import jax\n",
        "from jax import numpy as jp # Standard alias for jax.numpy\n",
        "import jax.numpy as jnp # Keep jnp if used extensively, or switch to jp\n",
        "from matplotlib import pyplot as plt\n",
        "import mediapy as media\n",
        "from ml_collections import config_dict\n",
        "import mujoco\n",
        "from mujoco import mjx\n",
        "import numpy as np\n",
        "from orbax import checkpoint as ocp\n",
        "import random\n",
        "import csv\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-VcRahnQvVr",
        "outputId": "870e7b9a-4e99-48ff-91e4-1f55d6cad6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoTLSx4cFRdy",
        "outputId": "dce22b59-767d-40de-c268-7c77d35e54f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting playground\n",
            "  Downloading playground-0.0.5-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: brax>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from playground) (0.12.4)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.11/dist-packages (from playground) (1.12.2)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.11/dist-packages (from playground) (0.10.6)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from playground) (0.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from playground) (5.4.0)\n",
            "Requirement already satisfied: ml-collections in /usr/local/lib/python3.11/dist-packages (from playground) (1.1.0)\n",
            "Requirement already satisfied: mujoco-mjx>=3.2.7 in /usr/local/lib/python3.11/dist-packages (from playground) (3.3.3)\n",
            "Requirement already satisfied: mujoco>=3.2.7 in /usr/local/lib/python3.11/dist-packages (from playground) (3.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from playground) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (1.4.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (6.0.1)\n",
            "Requirement already satisfied: jaxlib>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (0.5.1)\n",
            "Requirement already satisfied: jaxopt in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (0.8.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (2.0.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (0.11.15)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (1.15.3)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (2.6.4)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (4.6.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from brax>=0.12.1->playground) (4.14.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->playground) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->playground) (3.4.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.11/dist-packages (from mujoco>=3.2.7->playground) (2.9.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco>=3.2.7->playground) (3.1.9)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax->playground) (1.1.1)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax->playground) (0.1.74)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax->playground) (13.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax->playground) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax->playground) (0.1.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->playground) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->playground) (2.19.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=3.2.7->playground) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=3.2.7->playground) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=3.2.7->playground) (3.23.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax>=0.12.1->playground) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->brax>=0.12.1->playground) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax>=0.12.1->playground) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask->brax>=0.12.1->playground) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask->brax>=0.12.1->playground) (3.1.3)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->brax>=0.12.1->playground) (0.1.89)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->brax>=0.12.1->playground) (3.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx->brax>=0.12.1->playground) (24.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->brax>=0.12.1->playground) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->playground) (0.1.2)\n",
            "Downloading playground-0.0.5-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: playground\n",
            "Successfully installed playground-0.0.5\n"
          ]
        }
      ],
      "source": [
        "#@title Install MuJoCo Playground\n",
        "!pip install playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYm2h7m8w3Nv",
        "outputId": "2c40de61-81a1-4f47-987e-e9f12d3e0cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mujoco_menagerie not found. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning mujoco_menagerie: ██████████| 100/100 [00:37<00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking out commit 14ceccf557cc47240202f2354d684eca58ff8de4\n",
            "Successfully downloaded mujoco_menagerie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Import The Playground\n",
        "\n",
        "from mujoco_playground import wrapper\n",
        "from mujoco_playground import registry\n",
        "from mujoco_playground.config import locomotion_params # Import here for easier access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "uRp0kSzlLzWo",
        "outputId": "0f838bda-2809-4c50-f55c-ddeb1921a553"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzsm7\u001b[0m (\u001b[33mzsm7-the-university-of-texas-at-austin\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250624_024222-kta2ib6h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zsm7-the-university-of-texas-at-austin/epo-mujoco-playground/runs/kta2ib6h' target=\"_blank\">lunar-grass-66</a></strong> to <a href='https://wandb.ai/zsm7-the-university-of-texas-at-austin/epo-mujoco-playground' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zsm7-the-university-of-texas-at-austin/epo-mujoco-playground' target=\"_blank\">https://wandb.ai/zsm7-the-university-of-texas-at-austin/epo-mujoco-playground</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zsm7-the-university-of-texas-at-austin/epo-mujoco-playground/runs/kta2ib6h' target=\"_blank\">https://wandb.ai/zsm7-the-university-of-texas-at-austin/epo-mujoco-playground/runs/kta2ib6h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/zsm7-the-university-of-texas-at-austin/epo-mujoco-playground/runs/kta2ib6h?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a3d6d24ab10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#@title Import wandb\n",
        "import wandbc\n",
        "from IPython.display import display\n",
        "wandb.init(project=\"epo-mujoco-playground\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UfGH70ySkU-"
      },
      "source": [
        "## Google Drive Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBMsUa10Sl4W",
        "outputId": "37432be6-7d26-4e33-9324-9adfb43fb5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results will be saved to: /content/EPO_results/\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "DRIVE_PATH = \"/content/EPO_results/\"\n",
        "# try:\n",
        "#     # Mount Google Drive if not already mounted and in Colab\n",
        "#     if 'google.colab' in str(get_ipython()):\n",
        "#         drive.mount('/content/drive')\n",
        "#         DRIVE_PATH = \"/content/drive/MyDrive/EPO_results/\" # Example path in Drive\n",
        "#     else:\n",
        "#         print(\"Not in Colab, using local path for DRIVE_PATH.\")\n",
        "# except NameError: # get_ipython is not defined if not in an IPython environment\n",
        "#     print(\"Not in an IPython environment, using local path for DRIVE_PATH.\")\n",
        "\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "print(f\"Results will be saved to: {DRIVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcibXbyKt4FI"
      },
      "source": [
        "# Environments and Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox0Gze9Ct5AM",
        "outputId": "297e96da-1d7e-41fd-bbe8-fe1ac9154ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ApolloJoystickFlatTerrain', 'BarkourJoystick', 'BerkeleyHumanoidJoystickFlatTerrain', 'BerkeleyHumanoidJoystickRoughTerrain', 'G1JoystickFlatTerrain', 'G1JoystickRoughTerrain', 'Go1JoystickFlatTerrain', 'Go1JoystickRoughTerrain', 'Go1Getup', 'Go1Handstand', 'Go1Footstand', 'H1InplaceGaitTracking', 'H1JoystickGaitTracking', 'Op3Joystick', 'SpotFlatTerrainJoystick', 'SpotGetup', 'SpotJoystickGaitTracking', 'T1JoystickFlatTerrain', 'T1JoystickRoughTerrain')\n"
          ]
        }
      ],
      "source": [
        "# List of environments in MuJoCo Playground suite\n",
        "print(registry.locomotion.ALL_ENVS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jslROTF8m9yO_cleaned"
      },
      "outputs": [],
      "source": [
        "# Helper method to extract action from policy output (consolidated)\n",
        "def extract_action_from_policy(policy_out):\n",
        "    \"\"\"Return the action as a JAX array, no matter what else is bundled with it.\"\"\"\n",
        "    if isinstance(policy_out, (jax.Array, jnp.ndarray)):\n",
        "        return jnp.asarray(policy_out)          # already the action\n",
        "    elif isinstance(policy_out, (tuple, list)):\n",
        "        return jnp.asarray(policy_out[0])       # first element is the action\n",
        "    else:\n",
        "        raise TypeError(f\"Unexpected policy output type: {type(policy_out)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWFSAGBkkmIb_cleaned"
      },
      "outputs": [],
      "source": [
        "# This make_safe_policy is used by record_video.\n",
        "# It ensures the policy returns only the action array and puts it on device.\n",
        "# Note: The ppo.make_inference_fn typically returns a function that itself returns (action, extra_data_tuple).\n",
        "# So, policy_fn(obs, rng) already gives a tuple. extract_action_from_policy handles this.\n",
        "\n",
        "def make_safe_policy_for_video(policy_fn_tuple_output):\n",
        "    \"\"\"Wraps a policy function to ensure it returns a JAX array action, placed on device.\"\"\"\n",
        "    def safe_policy(obs, rng):\n",
        "        raw_out = policy_fn_tuple_output(obs, rng) # This should be (action, _)\n",
        "        act = extract_action_from_policy(raw_out)\n",
        "        return jax.device_put(act)\n",
        "    return safe_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjSt0QkXQFpe_cleaned"
      },
      "outputs": [],
      "source": [
        "def record_video(params, inference_fn_factory, env_name, env_cfg=None, path=\"ppo_epo_video.mp4\", seed=0, max_steps=500):\n",
        "    \"\"\"Records a video of the policy in action.\"\"\"\n",
        "    if env_cfg:\n",
        "        eval_env = registry.load(env_name, config=env_cfg)\n",
        "    else:\n",
        "        eval_env = registry.load(env_name)\n",
        "\n",
        "    # inference_fn_factory is ppo.make_inference_fn\n",
        "    # It takes params and returns a policy function policy_fn(observations, rng_key)\n",
        "    policy_fn_raw = inference_fn_factory(params) # This policy returns (action, extras)\n",
        "\n",
        "    # Wrap it to get only the action array, on device, for stepping the environment\n",
        "    safe_policy_for_stepping = make_safe_policy_for_video(policy_fn_raw)\n",
        "\n",
        "    frames = []\n",
        "    rng = jax.random.PRNGKey(seed)\n",
        "    state = eval_env.reset(rng=rng)\n",
        "\n",
        "    for step_count in range(max_steps):\n",
        "        img = eval_env.render(state) # Render current state before action\n",
        "        frames.append(img)\n",
        "\n",
        "        if state.done:\n",
        "            if hasattr(state, 'info') and state.info.get('truncation', False) and step_count < max_steps -1:\n",
        "                 print(f\"Episode truncated at step {step_count} before max_steps.\")\n",
        "            else:\n",
        "                 print(f\"Episode naturally done at step {step_count}.\")\n",
        "            break\n",
        "\n",
        "        rng, key_sample = jax.random.split(rng)\n",
        "        action = safe_policy_for_stepping(state.obs, key_sample)\n",
        "        state = eval_env.step(state, action)\n",
        "\n",
        "    if step_count == max_steps - 1 and not state.done:\n",
        "        print(f\"Video recording reached max_steps ({max_steps}) without episode termination.\")\n",
        "        # Render the last state if loop finished due to max_steps\n",
        "        img = eval_env.render(state)\n",
        "        frames.append(img)\n",
        "\n",
        "    media.write_video(path, frames, fps=1.0 / eval_env.dt)\n",
        "    print(f\"Video saved to {path}\")\n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK4Ddan5nvaz_MODIFIED"
      },
      "outputs": [],
      "source": [
        "# MODIFIED evaluate_params function\n",
        "def evaluate_params(params: Any,\n",
        "                    inference_fn_factory: Callable, # e.g., ppo.make_inference_fn\n",
        "                    env_name: str,\n",
        "                    env_config: Optional[config_dict.ConfigDict] = None,\n",
        "                    seed: int = 0,\n",
        "                    num_episodes: int = 5,\n",
        "                    default_max_steps_override: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Roll out `num_episodes` episodes with the policy defined by `params`\n",
        "    and return the mean episode reward.\n",
        "    inference_fn_factory is a function like ppo.make_inference_fn or sac.make_inference_fn\n",
        "    \"\"\"\n",
        "    if env_config:\n",
        "        env = registry.load(env_name, config=env_config)\n",
        "    else:\n",
        "        env = registry.load(env_name)\n",
        "\n",
        "    # policy_raw is a function: policy_raw(observations, rng_key) -> (actions, extras)\n",
        "    policy_raw = inference_fn_factory(params)\n",
        "\n",
        "    max_steps_per_episode = default_max_steps_override\n",
        "    if max_steps_per_episode is None: # Only try to infer if not overridden\n",
        "        if env_config and hasattr(env_config, 'episode_length'):\n",
        "            max_steps_per_episode = env_config.episode_length\n",
        "        elif hasattr(env, '_episode_length'):\n",
        "            max_steps_per_episode = env._episode_length\n",
        "        elif hasattr(env, 'max_episode_steps'):\n",
        "            max_steps_per_episode = env.max_episode_steps\n",
        "        else:\n",
        "            max_steps_per_episode = 1000 # Fallback if no other length found\n",
        "\n",
        "    # print(f\"Evaluating {env_name} with max_steps_per_episode = {max_steps_per_episode}\") # Verbose, can be enabled for debugging\n",
        "\n",
        "    rewards_all_episodes = []\n",
        "    for epi in range(num_episodes):\n",
        "        episode_rng = jax.random.PRNGKey(seed + epi)\n",
        "        state = env.reset(rng=episode_rng)\n",
        "\n",
        "        current_ep_reward = 0.0\n",
        "        done = False\n",
        "        truncated = False\n",
        "        current_step = 0\n",
        "\n",
        "        action_rng = episode_rng\n",
        "\n",
        "        while not (done or truncated):\n",
        "            if current_step >= max_steps_per_episode:\n",
        "                # print(f\"Episode {epi+1} truncated by max_steps_per_episode ({max_steps_per_episode} steps).\")\n",
        "                break\n",
        "\n",
        "            action_rng, key_sample = jax.random.split(action_rng)\n",
        "\n",
        "            raw_policy_output = policy_raw(state.obs, key_sample)\n",
        "            act = extract_action_from_policy(raw_policy_output)\n",
        "            act = jax.device_put(act)\n",
        "\n",
        "            state = env.step(state, act)\n",
        "            current_ep_reward += float(state.reward)\n",
        "            done = bool(state.done)\n",
        "\n",
        "            if hasattr(state, 'info') and isinstance(state.info, dict):\n",
        "                truncated = bool(state.info.get('truncation', False))\n",
        "\n",
        "            current_step += 1\n",
        "        rewards_all_episodes.append(current_ep_reward)\n",
        "\n",
        "    if not rewards_all_episodes:\n",
        "        return 0.0\n",
        "    return sum(rewards_all_episodes) / len(rewards_all_episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQLXn3ICSY4W"
      },
      "outputs": [],
      "source": [
        "from brax.envs.wrappers.training import VmapWrapper, EpisodeWrapper\n",
        "from typing import Any, Callable, Optional\n",
        "from ml_collections import config_dict\n",
        "import jax\n",
        "import jax.numpy as jp\n",
        "from mujoco_playground import registry\n",
        "\n",
        "# Ensure extract_action_from_policy is defined globally or imported correctly\n",
        "\n",
        "def vectorized_evaluate_params(\n",
        "    params: Any,\n",
        "    inference_fn_factory: Callable,\n",
        "    env_name: str,\n",
        "    env_config: Optional[config_dict.ConfigDict] = None,\n",
        "    ppo_config_for_eval: Optional[config_dict.ConfigDict] = None,\n",
        "    seed: int = 0,\n",
        "    num_parallel_episodes: int = 5,\n",
        "    default_max_steps_override: Optional[int] = None\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Roll out `num_parallel_episodes` in parallel using a vectorized environment\n",
        "    and return the mean episode reward.\n",
        "    \"\"\"\n",
        "\n",
        "    def env_factory_for_eval():\n",
        "        if env_config:\n",
        "            return registry.load(env_name, config=env_config)\n",
        "        return registry.load(env_name)\n",
        "\n",
        "    base_env_instance = env_factory_for_eval()\n",
        "\n",
        "    max_steps_for_episode_logic = default_max_steps_override\n",
        "    if max_steps_for_episode_logic is None:\n",
        "        if ppo_config_for_eval and hasattr(ppo_config_for_eval, 'episode_length'):\n",
        "            max_steps_for_episode_logic = ppo_config_for_eval.episode_length\n",
        "        elif env_config and hasattr(env_config, 'episode_length'):\n",
        "            max_steps_for_episode_logic = env_config.episode_length\n",
        "        elif hasattr(base_env_instance, '_episode_length'):\n",
        "            max_steps_for_episode_logic = base_env_instance._episode_length\n",
        "        elif hasattr(base_env_instance, 'max_episode_steps'):\n",
        "            max_steps_for_episode_logic = base_env_instance.max_episode_steps\n",
        "        else:\n",
        "            max_steps_for_episode_logic = 1000\n",
        "\n",
        "    current_action_repeat = 1\n",
        "    if ppo_config_for_eval and hasattr(ppo_config_for_eval, 'action_repeat'):\n",
        "        current_action_repeat = ppo_config_for_eval.action_repeat\n",
        "    elif env_config and hasattr(env_config, 'action_repeat'):\n",
        "        current_action_repeat = env_config.action_repeat\n",
        "    elif hasattr(base_env_instance, 'action_repeat'):\n",
        "        current_action_repeat = base_env_instance.action_repeat\n",
        "\n",
        "    # Wrap the single base_env_instance with EpisodeWrapper.\n",
        "    # This ensures info['steps'] etc. are scalars in the context of the single env.\n",
        "    episode_aware_single_env = EpisodeWrapper(\n",
        "        base_env_instance,\n",
        "        episode_length=max_steps_for_episode_logic,\n",
        "        action_repeat=current_action_repeat\n",
        "    )\n",
        "\n",
        "    #    VmapWrapper will handle the single RNG key correctly\n",
        "    #    and jax.vmap will correctly batch all fields of the State PyTree,\n",
        "    #    including info['steps'] which will become a batched array.\n",
        "    eval_env = VmapWrapper(\n",
        "        episode_aware_single_env, # Pass the already episode-wrapped single env\n",
        "        batch_size=num_parallel_episodes\n",
        "    )\n",
        "\n",
        "    policy = inference_fn_factory(params)\n",
        "\n",
        "    @jax.jit\n",
        "    def jit_env_rollout(initial_states_batched, per_step_rng_keys):\n",
        "\n",
        "        def scan_fn_for_rollout(carry_batched_states, rng_key_for_this_step):\n",
        "            policy_outputs_batched = policy(carry_batched_states.obs, rng_key_for_this_step)\n",
        "            acts_batched = extract_action_from_policy(policy_outputs_batched)\n",
        "            next_batched_states = eval_env.step(carry_batched_states, acts_batched) # eval_env is now VmapWrapper\n",
        "            return next_batched_states, next_batched_states.reward\n",
        "\n",
        "        final_batched_states, step_rewards_matrix = jax.lax.scan(\n",
        "            scan_fn_for_rollout,\n",
        "            initial_states_batched,\n",
        "            per_step_rng_keys,\n",
        "            length=max_steps_for_episode_logic\n",
        "        )\n",
        "\n",
        "        total_rewards_per_parallel_run = jp.sum(step_rewards_matrix, axis=0)\n",
        "        return total_rewards_per_parallel_run\n",
        "\n",
        "    key = jax.random.PRNGKey(seed)\n",
        "    key_reset_batch, key_rollout_root = jax.random.split(key)\n",
        "\n",
        "    # This now calls VmapWrapper.reset(key_reset_batch)\n",
        "    initial_states_batched = eval_env.reset(key_reset_batch)\n",
        "\n",
        "    per_step_rng_keys_for_scan = jax.random.split(key_rollout_root, max_steps_for_episode_logic)\n",
        "    all_episode_total_rewards = jit_env_rollout(initial_states_batched, per_step_rng_keys_for_scan)\n",
        "    mean_return = jp.mean(all_episode_total_rewards)\n",
        "    max_return = jp.max(all_episode_total_rewards)\n",
        "\n",
        "    total_samples = num_parallel_episodes * max_steps_for_episode_logic * current_action_repeat\n",
        "\n",
        "    return float(mean_return), float(max_return), int(total_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znVHSJ6v_fgy"
      },
      "source": [
        "#  Handstand Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYriZOAxzEk_Config",
        "outputId": "d5c81f44-5c15-49c1-907c-9a4bf20ef3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Env Config for Go1Footstand:\n",
            "{'Kd': 0.5, 'Kp': 35.0, 'action_repeat': 1, 'action_scale': 0.3, 'ctrl_dt': 0.02, 'energy_termination_threshold': inf, 'episode_length': 500, 'init_from_crouch': 0.0, 'noise_config': {'level': 1.0, 'scales': {'gravity': 0.05, 'gyro': 0.2, 'joint_pos': 0.01, 'joint_vel': 1.5, 'linvel': 0.1}}, 'reward_config': {'scales': {'action_rate': 0.0, 'contact': -0.1, 'dof_acc': 0.0, 'dof_pos_limits': -0.5, 'energy': 0.0, 'height': 1.0, 'orientation': 1.0, 'pose': -0.1, 'stay_still': 0.0, 'termination': 0.0, 'torques': 0.0}}, 'sim_dt': 0.004, 'soft_joint_pos_limit_factor': 0.9}\n",
            "\n",
            "Default PPO Params for Go1Footstand:\n",
            "{'action_repeat': 1, 'batch_size': 256, 'discounting': 0.97, 'entropy_cost': 0.01, 'episode_length': 500, 'learning_rate': 0.0003, 'max_grad_norm': 1.0, 'network_factory': {'policy_hidden_layer_sizes': (512, 256, 128), 'policy_obs_key': 'state', 'value_hidden_layer_sizes': (512, 256, 128), 'value_obs_key': 'privileged_state'}, 'normalize_observations': True, 'num_envs': 8192, 'num_evals': 5, 'num_minibatches': 32, 'num_timesteps': 100000000, 'num_updates_per_batch': 4, 'reward_scaling': 1.0, 'unroll_length': 20}\n",
            "\n",
            "Default episode length from PPO params: 500\n",
            "Calculated FINETUNE_TIMESTEPS_EPO: 500\n"
          ]
        }
      ],
      "source": [
        "# Centralized configuration for Go1Handstand experiments\n",
        "ENV_NAME_HANDSTAND = 'Go1Footstand' # 'Go1Handstand' or 'SpotGetup' for the other tasks\n",
        "\n",
        "# Load default environment configuration\n",
        "ENV_CFG_HANDSTAND_DEFAULT = registry.get_default_config(ENV_NAME_HANDSTAND)\n",
        "\n",
        "# Load default PPO parameters for this environment\n",
        "PPO_PARAMS_HANDSTAND_DEFAULT = locomotion_params.brax_ppo_config(ENV_NAME_HANDSTAND)\n",
        "\n",
        "# Common experiment settings\n",
        "SEED_GLOBAL = 42\n",
        "TOTAL_TIMESTEPS_EXPERIMENT = 30_000_000\n",
        "\n",
        "# Determine finetune timesteps for EPO based on PPO default unroll_length if available\n",
        "# This ensures a few updates happen during finetuning.\n",
        "ppo_unroll_length = PPO_PARAMS_HANDSTAND_DEFAULT.get('unroll_length', 20) # Default to 20 if not in config\n",
        "num_updates_finetune = 25 # Number of PPO updates during finetuning\n",
        "\n",
        "# FINETUNE_TIMESTEPS_EPO = ppo_unroll_length * num_updates_finetune\n",
        "FINETUNE_TIMESTEPS_EPO = 500\n",
        "\n",
        "print(f\"Default Env Config for {ENV_NAME_HANDSTAND}:\\n{ENV_CFG_HANDSTAND_DEFAULT.to_dict()}\")\n",
        "print(f\"\\nDefault PPO Params for {ENV_NAME_HANDSTAND}:\\n{PPO_PARAMS_HANDSTAND_DEFAULT.to_dict()}\")\n",
        "print(f\"\\nDefault episode length from PPO params: {PPO_PARAMS_HANDSTAND_DEFAULT.episode_length}\")\n",
        "print(f\"Calculated FINETUNE_TIMESTEPS_EPO: {FINETUNE_TIMESTEPS_EPO}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nB5ugbdS5kk"
      },
      "source": [
        "Create a checkpoint directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyEDpHisS7eO",
        "outputId": "56bc60d4-ac41-44c6-88ec-c74bbd75839c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoints for Go1Footstand will be saved in: /content/checkpoints/Go1Footstand\n"
          ]
        }
      ],
      "source": [
        "ckpt_path_handstand = epath.Path(\"checkpoints\").resolve() / ENV_NAME_HANDSTAND\n",
        "ckpt_path_handstand.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Checkpoints for {ENV_NAME_HANDSTAND} will be saved in: {ckpt_path_handstand}\")\n",
        "\n",
        "try:\n",
        "    with open(ckpt_path_handstand / \"default_env_config.json\", \"w\") as fp:\n",
        "      json.dump(ENV_CFG_HANDSTAND_DEFAULT.to_dict(), fp, indent=4)\n",
        "    with open(ckpt_path_handstand / \"default_ppo_params.json\", \"w\") as fp:\n",
        "      json.dump(PPO_PARAMS_HANDSTAND_DEFAULT.to_dict(), fp, indent=4)\n",
        "except Exception as e:\n",
        "    print(f\"Error saving default configs to JSON: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE7iL3AhQZZ5"
      },
      "source": [
        "# Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTKCZoYdPJfS"
      },
      "source": [
        "## PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd059tKzcsFj_MODIFIED"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "from datetime import datetime\n",
        "from typing import Any, Callable, Optional\n",
        "from etils import epath\n",
        "from flax.training import orbax_utils\n",
        "from IPython.display import HTML, clear_output, display\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "from ml_collections import config_dict\n",
        "import orbax.checkpoint as ocp # Make sure ocp is imported\n",
        "import os # For path manipulation and deletion\n",
        "import uuid # For unique temporary checkpoint names\n",
        "\n",
        "# Assuming ppo_networks, ppo (for ppo.train), registry, wrapper are imported elsewhere as in your notebook\n",
        "\n",
        "def train_ppo(env_name: str,\n",
        "                num_timesteps: int,\n",
        "                env_cfg: config_dict.ConfigDict,\n",
        "                ppo_cfg: config_dict.ConfigDict,\n",
        "                seed: int = 0,\n",
        "                ckpt_dir_base: str = \"checkpoints\",\n",
        "                initial_params: Optional[Any] = None, # For starting from existing params (e.g., in EPO fine-tuning)\n",
        "                restore_checkpoint_path: Optional[str] = None, # For restoring from a user-specified file\n",
        "                enable_progress_display: bool = True):\n",
        "    \"\"\"Trains a PPO agent, with support for starting from initial_params for fine-tuning.\"\"\"\n",
        "\n",
        "    current_ppo_params = config_dict.ConfigDict(ppo_cfg) # Use a copy\n",
        "    current_ppo_params.num_timesteps = num_timesteps\n",
        "    current_ppo_params.seed = seed\n",
        "\n",
        "    ckpt_path_env_base = epath.Path(ckpt_dir_base).resolve() / env_name\n",
        "    ckpt_path_env_base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Path for periodic checkpoints during this training run\n",
        "    # Differentiate these from any temporary fine-tuning checkpoints\n",
        "    run_specific_ckpt_path = ckpt_path_env_base / f\"run_seed_{seed}_ts_{num_timesteps}\"\n",
        "    run_specific_ckpt_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    x_data, y_data, y_dataerr = [], [], []\n",
        "    times = [datetime.now()]\n",
        "\n",
        "    def _policy_params_fn(current_step, make_policy_unused, params_to_save):\n",
        "        # Saves periodic checkpoints *during* the current PPO training run\n",
        "        orbax_checkpointer = ocp.PyTreeCheckpointer()\n",
        "        save_args = orbax_utils.save_args_from_target(params_to_save)\n",
        "        path = run_specific_ckpt_path / f\"step_{current_step}\"\n",
        "        try:\n",
        "            orbax_checkpointer.save(path, params_to_save, force=True, save_args=save_args)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving periodic checkpoint at step {current_step}: {e}\")\n",
        "\n",
        "    def _progress(num_steps, metrics):\n",
        "        if not enable_progress_display: return\n",
        "        try:\n",
        "            clear_output(wait=True)\n",
        "            times.append(datetime.now())\n",
        "            x_data.append(num_steps)\n",
        "            y_data.append(metrics[\"eval/episode_reward\"])\n",
        "            y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "            # print rewards and current timesteps\n",
        "            print(f\"Timesteps: {num_steps}, Reward: {metrics['eval/episode_reward']}\")\n",
        "\n",
        "            plt.figure(figsize=(8,5))\n",
        "            plt.xlim([0, current_ppo_params.num_timesteps * 1.05])\n",
        "            plt.xlabel(\"# environment steps\")\n",
        "            plt.ylabel(\"reward per episode\")\n",
        "            plt.title(f\"Training: {env_name} - Seed {seed} - Step {num_steps}\\\\nEval Reward: {y_data[-1]:.3f}\")\n",
        "            plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\", ecolor='lightblue', elinewidth=1, capsize=3)\n",
        "            plt.grid(True)\n",
        "            display(plt.gcf())\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error in progress plot: {e}\")\n",
        "\n",
        "    network_factory_kwargs = current_ppo_params.get('network_factory_kwargs', {})\n",
        "    network_factory = functools.partial(ppo_networks.make_ppo_networks, **network_factory_kwargs)\n",
        "\n",
        "    train_fn_params_dict = current_ppo_params.to_dict()\n",
        "    train_fn_params_dict.pop('network_factory_kwargs', None)\n",
        "    train_fn_params_dict.pop('network_factory', None) # Remove if it was just a placeholder\n",
        "\n",
        "    randomizer = registry.get_domain_randomizer(env_name)\n",
        "\n",
        "    # Handle initial_params for fine-tuning via temporary checkpoint\n",
        "    effective_restore_path = restore_checkpoint_path\n",
        "    temp_checkpoint_dir = None # Keep track of temporary directory for cleanup\n",
        "\n",
        "    if initial_params is not None:\n",
        "        if restore_checkpoint_path is not None:\n",
        "            print(f\"Warning: Both 'initial_params' and 'restore_checkpoint_path' were provided to train_ppo. \"\n",
        "                  f\"'initial_params' will be used for fine-tuning, overriding '{restore_checkpoint_path}'.\")\n",
        "\n",
        "        temp_checkpoint_base = ckpt_path_env_base / \"temp_finetune_checkpoints\"\n",
        "        temp_checkpoint_base.mkdir(parents=True, exist_ok=True)\n",
        "        # Unique directory for this specific fine-tuning instance\n",
        "        temp_checkpoint_dir = temp_checkpoint_base / str(uuid.uuid4())\n",
        "        temp_checkpoint_dir.mkdir()\n",
        "\n",
        "        print(f\"Fine-tuning: Temporarily saving initial_params to {temp_checkpoint_dir} for PPO to load.\")\n",
        "        try:\n",
        "            checkpointer = ocp.PyTreeCheckpointer()\n",
        "            save_args = orbax_utils.save_args_from_target(initial_params)\n",
        "            checkpointer.save(temp_checkpoint_dir, initial_params, save_args=save_args, force=True)\n",
        "            effective_restore_path = str(temp_checkpoint_dir)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving initial_params to temporary checkpoint: {e}. Proceeding without restoring them.\")\n",
        "            effective_restore_path = None # Fallback if saving fails\n",
        "            if temp_checkpoint_dir and temp_checkpoint_dir.exists(): # Clean up if dir was made but save failed\n",
        "                 try:\n",
        "                    for item in temp_checkpoint_dir.iterdir(): item.unlink() # Delete files if any\n",
        "                    temp_checkpoint_dir.rmdir()\n",
        "                 except Exception as cleanup_e:\n",
        "                    print(f\"Error cleaning up temp checkpoint dir after save failure: {cleanup_e}\")\n",
        "            temp_checkpoint_dir = None\n",
        "\n",
        "    train_fn = functools.partial(\n",
        "        ppo.train,\n",
        "        **train_fn_params_dict,\n",
        "        network_factory=network_factory,\n",
        "        randomization_fn=randomizer,\n",
        "        progress_fn=_progress,\n",
        "        policy_params_fn=_policy_params_fn,\n",
        "    )\n",
        "\n",
        "    make_inference_fn_out, trained_params, metrics_out = train_fn(\n",
        "        environment=registry.load(env_name, config=env_cfg),\n",
        "        eval_env=registry.load(env_name, config=env_cfg),\n",
        "        wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        "        restore_checkpoint_path=effective_restore_path # Use the determined path\n",
        "    )\n",
        "\n",
        "    # Cleanup temporary checkpoint if one was created\n",
        "    if temp_checkpoint_dir is not None and temp_checkpoint_dir.exists():\n",
        "        print(f\"Fine-tuning: Cleaning up temporary checkpoint at {temp_checkpoint_dir}\")\n",
        "        try:\n",
        "            # Orbax PyTreeCheckpointer might create subdirectories or specific files like 'metadata', 'checkpoint'\n",
        "            # A robust way to remove is to iterate and delete, then rmdir.\n",
        "            # For simplicity here, if using epath, rmtree is safer.\n",
        "            # Since temp_checkpoint_dir is an epath.Path object:\n",
        "            if any(temp_checkpoint_dir.iterdir()): # Check if not empty\n",
        "                 # If using standard os, you'd need shutil.rmtree\n",
        "                 # With epath, it should handle directory removal, but let's be careful\n",
        "                 # For PyTreeCheckpointer, it saves files like 'checkpoint', 'metadata' directly in the path provided.\n",
        "                 for item in temp_checkpoint_dir.iterdir():\n",
        "                     if item.is_file():\n",
        "                         item.unlink()\n",
        "                     # Add handling for subdirs if PyTreeCheckpointer creates them, though usually not for simple saves.\n",
        "            temp_checkpoint_dir.rmdir() # Remove the now-empty unique directory\n",
        "        except Exception as e:\n",
        "            print(f\"Error cleaning up temporary checkpoint directory {temp_checkpoint_dir}: {e}\")\n",
        "\n",
        "\n",
        "    if enable_progress_display and times and len(times) > 1:\n",
        "        print(f\"Time to JIT: {times[1] - times[0]}\")\n",
        "        print(f\"Time to Train: {times[-1] - times[1]}\")\n",
        "    elif enable_progress_display:\n",
        "        print(\"Training duration info not available (likely a very short run).\")\n",
        "\n",
        "    return make_inference_fn_out, trained_params, metrics_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ox5VTZaR_le_MODIFIED"
      },
      "outputs": [],
      "source": [
        "# MODIFIED PPO Baseline with logging\n",
        "def train_ppo_baseline(env_name: str,\n",
        "                         total_timesteps: int,\n",
        "                         env_cfg: config_dict.ConfigDict,\n",
        "                         ppo_cfg: config_dict.ConfigDict,\n",
        "                         seed: int = 0,\n",
        "                         wandb_project: Optional[str] = \"Brax-PPO-Baseline\",\n",
        "                         enable_wandb: bool = False):\n",
        "    if enable_wandb:\n",
        "        try:\n",
        "            wandb.init(project=wandb_project, config={\n",
        "                \"env\": env_name,\n",
        "                \"total_timesteps\": total_timesteps,\n",
        "                \"seed\": seed,\n",
        "                \"env_config\": env_cfg.to_dict(),\n",
        "                \"ppo_config\": ppo_cfg.to_dict()\n",
        "            }, reinit=True, name=f\"PPO_{env_name}_seed{seed}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Wandb init failed: {e}\")\n",
        "            enable_wandb = False # Disable wandb if init fails\n",
        "\n",
        "    inference_fn_factory, trained_params, metrics = train_ppo(\n",
        "        env_name=env_name,\n",
        "        num_timesteps=total_timesteps,\n",
        "        env_cfg=env_cfg,\n",
        "        ppo_cfg=ppo_cfg,\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    mean_reward, final_reward, _ = vectorized_evaluate_params( # Call the new function\n",
        "        params=trained_params,\n",
        "        inference_fn_factory=inference_fn_factory,\n",
        "        env_name=env_name,\n",
        "        env_config=env_cfg,\n",
        "        seed=seed + 1000,\n",
        "        num_parallel_episodes=5, # Or a suitable number for final eval\n",
        "        default_max_steps_override=ppo_cfg.episode_length\n",
        "    )\n",
        "    print(f\"PPO Baseline Final Evaluation Reward (Seed {seed}): {final_reward}\")\n",
        "\n",
        "    if enable_wandb:\n",
        "        try:\n",
        "            wandb.log({\"final_reward\": final_reward, \"training_metrics\": metrics if metrics else {}})\n",
        "            video_local_path = f\"ppo_baseline_{env_name}_seed{seed}.mp4\"\n",
        "            video_path_drive = record_video(\n",
        "                params=trained_params,\n",
        "                inference_fn_factory=inference_fn_factory,\n",
        "                env_name=env_name,\n",
        "                env_cfg=env_cfg,\n",
        "                path=video_local_path,\n",
        "                seed=seed + 2000\n",
        "            )\n",
        "            wandb.log({\"final_video\": wandb.Video(video_path_drive, caption=f\"PPO Baseline {env_name} Seed {seed}\")})\n",
        "            # Move video to Drive\n",
        "            base_video_name = os.path.basename(video_path_drive)\n",
        "            dest_path = os.path.join(DRIVE_PATH, base_video_name)\n",
        "            if os.path.abspath(video_path_drive) != os.path.abspath(dest_path):\n",
        "                 # Ensure source exists before trying to move\n",
        "                if os.path.exists(video_path_drive):\n",
        "                    os.rename(video_path_drive, dest_path)\n",
        "                    print(f\"Moved video to {dest_path}\")\n",
        "                elif os.path.exists(dest_path):\n",
        "                    print(f\"Video already at drive path or original not found: {dest_path}\")\n",
        "                else:\n",
        "                    print(f\"Source video file not found: {video_path_drive}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Wandb logging/video handling failed: {e}\")\n",
        "        finally:\n",
        "            wandb.finish()\n",
        "\n",
        "    return trained_params, final_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SfxrhkpKqvX"
      },
      "source": [
        "## EPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GKEPCeoVsec_MODIFIED"
      },
      "outputs": [],
      "source": [
        "# Evolutionary operations and helper methods\n",
        "def copy_params(params: Any) -> Any:\n",
        "    return jax.tree_util.tree_map(lambda x: x.copy() if hasattr(x, 'copy') else x, params)\n",
        "\n",
        "def average_params(params1: Any, params2: Any, alpha: float = 0.5) -> Any:\n",
        "    return jax.tree_util.tree_map(lambda p1, p2: alpha * p1 + (1 - alpha) * p2, params1, params2)\n",
        "\n",
        "def crossover_params(parent1_params: Any, parent2_params: Any, fitness1: float, fitness2: float) -> Any:\n",
        "    total_fitness = fitness1 + fitness2 + 1e-8\n",
        "    alpha = fitness1 / total_fitness\n",
        "    return average_params(parent1_params, parent2_params, alpha=alpha)\n",
        "\n",
        "# Mutate params\n",
        "def mutate_params(params: Any, rng_key: jax.random.PRNGKey, mutation_scale: float = 0.1) -> Any:\n",
        "    # Create a tree of RNG keys, one for each leaf in the params pytree\n",
        "    tree_def = jax.tree_util.tree_structure(params)\n",
        "    leaves = jax.tree_util.tree_leaves(params)\n",
        "    keys = jax.random.split(rng_key, len(leaves))\n",
        "    keys_tree = jax.tree_util.tree_unflatten(tree_def, keys)\n",
        "\n",
        "    def _mutate_leaf(p_leaf, key_leaf):\n",
        "        return p_leaf + jax.random.normal(key_leaf, p_leaf.shape, dtype=p_leaf.dtype) * mutation_scale\n",
        "\n",
        "    return jax.tree_util.tree_map(_mutate_leaf, params, keys_tree)\n",
        "\n",
        "# Evolve offspring\n",
        "def evolve_offspring(\n",
        "    ranked_population: List[Tuple[float, Any]],\n",
        "    num_elites: int,\n",
        "    mutation_rate: float,\n",
        "    mutation_scale: float,\n",
        "    rng_key: jax.random.PRNGKey, # Master key for this offspring\n",
        "    env_name: str,\n",
        "    env_cfg: config_dict.ConfigDict,\n",
        "    ppo_cfg_finetune: config_dict.ConfigDict,\n",
        "    finetune_timesteps: int\n",
        ") -> Tuple[jax.random.PRNGKey, Any, bool]: # Return key, child, and if finetuning occurred\n",
        "\n",
        "    next_rng_key, key_selection, key_crossover, key_mutation_decision, key_mutation, key_finetune_seed_gen = jax.random.split(rng_key, 6)\n",
        "\n",
        "    elite_fitnesses = [item[0] for item in ranked_population[:num_elites]]\n",
        "    elite_params_list = [item[1] for item in ranked_population[:num_elites]]\n",
        "\n",
        "    parent_indices = jax.random.choice(key_selection, jnp.arange(num_elites), shape=(2,), replace=False)\n",
        "    p1_params, p2_params = elite_params_list[parent_indices[0]], elite_params_list[parent_indices[1]]\n",
        "    f1, f2 = elite_fitnesses[parent_indices[0]], elite_fitnesses[parent_indices[1]]\n",
        "\n",
        "    child_params = crossover_params(p1_params, p2_params, f1, f2)\n",
        "\n",
        "    # Mutation OR Finetuning\n",
        "    finetuned_this_offspring = False\n",
        "    if jax.random.uniform(key_mutation_decision) < mutation_rate:\n",
        "        # print(\"Applying mutation...\")\n",
        "        child_params = mutate_params(child_params, key_mutation, mutation_scale)\n",
        "        did_finetune = finetuned_this_offspring\n",
        "    else:\n",
        "        # print(f\"Finetuning offspring for {finetune_timesteps} timesteps...\")\n",
        "        finetune_seed_int = int(jax.random.randint(key_finetune_seed_gen, (), 0, 1_000_000))\n",
        "\n",
        "        # It takes initial_params\n",
        "        _, finetuned_child_params, _ = train_ppo(\n",
        "            env_name=env_name,\n",
        "            num_timesteps=finetune_timesteps,\n",
        "            env_cfg=env_cfg,\n",
        "            ppo_cfg=ppo_cfg_finetune,\n",
        "            seed=finetune_seed_int,\n",
        "            initial_params=child_params, # Pass the crossed-over child for finetuning\n",
        "            enable_progress_display=False\n",
        "        )\n",
        "        child_params = finetuned_child_params\n",
        "        finetuned_this_offspring = True\n",
        "        did_finetune = finetuned_this_offspring\n",
        "\n",
        "    return next_rng_key, child_params, did_finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smt7h13afLQR"
      },
      "outputs": [],
      "source": [
        "def run_epo_brax(env_name: str,\n",
        "                 total_training_budget: int,\n",
        "                 env_cfg: config_dict.ConfigDict,\n",
        "                 ppo_cfg_pretrain: config_dict.ConfigDict,\n",
        "                 ppo_cfg_finetune: config_dict.ConfigDict,\n",
        "                 population_size: int = 8,\n",
        "                 num_elites: int = 3,\n",
        "                 pretrain_timesteps: int = 30000,\n",
        "                 finetune_timesteps_per_offspring: int = 500,\n",
        "                 mutation_rate: float = 0.3,\n",
        "                 mutation_scale: float = 0.1,\n",
        "                 seed: int = 0,\n",
        "                 wandb_project: Optional[str] = \"Brax-EPO\",\n",
        "                 enable_wandb: bool = False):\n",
        "\n",
        "    if num_elites < 0: num_elites = 0\n",
        "    if num_elites > population_size: num_elites = population_size\n",
        "    if population_size <= 0:\n",
        "        print(\"Error: population_size must be positive.\")\n",
        "        return None, [], None\n",
        "\n",
        "    # Wandb and RNG Initialization\n",
        "    if enable_wandb:\n",
        "        try:\n",
        "            wandb.init(project=wandb_project, config={\n",
        "                \"env\": env_name, \"total_training_budget\": total_training_budget,\n",
        "                \"population_size\": population_size, \"num_elites\": num_elites,\n",
        "                \"pretrain_timesteps\": pretrain_timesteps,\n",
        "                \"finetune_timesteps_per_offspring\": finetune_timesteps_per_offspring,\n",
        "                \"mutation_rate\": mutation_rate, \"mutation_scale\": mutation_scale, \"seed\": seed,\n",
        "                \"env_config\": env_cfg.to_dict(),\n",
        "                \"ppo_cfg_pretrain\": ppo_cfg_pretrain.to_dict(),\n",
        "                \"ppo_cfg_finetune\": ppo_cfg_finetune.to_dict()\n",
        "            }, reinit=True, name=f\"EPO_{env_name}_seed{seed}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Wandb init failed: {e}\")\n",
        "            enable_wandb = False\n",
        "\n",
        "    print(f\"Initializing EPO (Seed {seed}) for {env_name}\")\n",
        "    master_rng_key = jax.random.PRNGKey(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    current_total_timesteps = 0\n",
        "\n",
        "    # Pre-train Initial Agent with PPO\n",
        "    print(f\"Pretraining initial agent for {pretrain_timesteps} timesteps...\")\n",
        "    key_pretrain_seed_gen, master_rng_key = jax.random.split(master_rng_key)\n",
        "    pretrain_seed_int = int(jax.random.randint(key_pretrain_seed_gen, (), 0, 1_000_000))\n",
        "    inference_fn_factory, base_params, _ = train_ppo(\n",
        "        env_name=env_name, num_timesteps=pretrain_timesteps, env_cfg=env_cfg,\n",
        "        ppo_cfg=ppo_cfg_pretrain, seed=pretrain_seed_int, enable_progress_display=True\n",
        "    )\n",
        "\n",
        "    # Initialize Population (P clones of base_model)\n",
        "    # this is because we are not evaluating sample efficiency in these tasks\n",
        "    # sim2real of simulation-trained policies with single GPU means no need to care about sample count\n",
        "    population = [copy_params(base_params) for _ in range(population_size)]\n",
        "\n",
        "    # Evaluate Initial Best\n",
        "    key_eval_initial_seed_gen, master_rng_key = jax.random.split(master_rng_key)\n",
        "    eval_seed_initial_int = int(jax.random.randint(key_eval_initial_seed_gen, (), 0, 1_000_000))\n",
        "    mean_fitness, best_fitness, init_eval_sample_count = vectorized_evaluate_params(\n",
        "          base_params, inference_fn_factory, env_name, env_cfg,\n",
        "          ppo_config_for_eval=ppo_cfg_pretrain, seed=eval_seed_initial_int,\n",
        "          num_parallel_episodes=5, default_max_steps_override=ppo_cfg_pretrain.episode_length\n",
        "    )\n",
        "    current_total_timesteps = pretrain_timesteps # Budget consumed by PPO\n",
        "    print(f\"PPO pre-train steps used: {current_total_timesteps}/{total_training_budget}) ---\")\n",
        "    print(f\"Initial pre-trained agent fitness: {mean_fitness}\")\n",
        "    best_agent_params = copy_params(base_params)\n",
        "    current_max_fitness = best_fitness\n",
        "    current_total_timesteps += init_eval_sample_count # Count pre-train evaluation samples\n",
        "\n",
        "    # Logging Setup\n",
        "    generation = 0\n",
        "    all_max_fitness_over_generations = [best_fitness]\n",
        "    csv_log_path = os.path.join(DRIVE_PATH, f\"epo_gen_log_{env_name}_seed{seed}.csv\")\n",
        "    with open(csv_log_path, \"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Generation\", \"TotalEnvSteps\", \"MaxFitness\", \"AvgFitness\"])\n",
        "        writer.writerow([0, current_total_timesteps, best_fitness, best_fitness])\n",
        "\n",
        "    # Evolutionary Loop\n",
        "    while current_total_timesteps < total_training_budget:\n",
        "        generation += 1\n",
        "        print(f\"--- EPO Gen {generation} ---\")\n",
        "\n",
        "        # Evaluate Population\n",
        "        key_eval_gen_seeds, master_rng_key = jax.random.split(master_rng_key)\n",
        "        eval_seeds_for_pop = [int(s) for s in jax.random.randint(key_eval_gen_seeds, (population_size,), 0, 1_000_000)]\n",
        "        fitness_scores = []\n",
        "        print(f\"Evaluating population {generation}...\")\n",
        "        for i, pop_member_params in enumerate(population):\n",
        "            mean_fitness, best_fitness, eval_sample_count = vectorized_evaluate_params(\n",
        "                pop_member_params, inference_fn_factory, env_name, env_cfg,\n",
        "                ppo_config_for_eval=ppo_cfg_pretrain, seed=eval_seeds_for_pop[i],\n",
        "                num_parallel_episodes=5, default_max_steps_override=ppo_cfg_pretrain.episode_length\n",
        "            )\n",
        "            fitness_scores.append(best_fitness)\n",
        "            current_total_timesteps += eval_sample_count\n",
        "\n",
        "        print(f\"Best fitness: {best_fitness}\")\n",
        "\n",
        "        ranked_population = sorted(zip(fitness_scores, population), key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        current_max_fitness = ranked_population[0][0] if ranked_population else -float('inf')\n",
        "        current_avg_fitness = np.mean(fitness_scores) if fitness_scores else -float('inf')\n",
        "        all_max_fitness_over_generations.append(current_max_fitness)\n",
        "\n",
        "        if current_max_fitness > best_fitness:\n",
        "            best_fitness = current_max_fitness\n",
        "            best_agent_params = copy_params(ranked_population[0][1])\n",
        "            print(f\"New best fitness in Gen {generation}: {best_fitness}\")\n",
        "\n",
        "        # Logging\n",
        "        if enable_wandb:\n",
        "            wandb.log({\"generation\": generation, \"total_env_steps\": current_total_timesteps,\n",
        "                         \"max_fitness_current_gen\": current_max_fitness,\n",
        "                         \"avg_fitness_current_gen\": current_avg_fitness,\n",
        "                         \"best_fitness_overall\": best_fitness})\n",
        "        with open(csv_log_path, \"a\", newline=\"\") as csvfile_append:\n",
        "            generation_writer = csv.writer(csvfile_append)\n",
        "            generation_writer.writerow([generation, current_total_timesteps, current_max_fitness, current_avg_fitness])\n",
        "\n",
        "        # Elitism\n",
        "        if num_elites > 0 and ranked_population:\n",
        "            elites = [copy_params(p) for _, p in ranked_population[:num_elites]]\n",
        "        else:\n",
        "            elites = []\n",
        "\n",
        "        # -Generate Offspring\n",
        "        offspring = []\n",
        "        num_offspring_to_generate = population_size - len(elites) # Number of new individuals needed\n",
        "\n",
        "        key_offspring_loop_master, master_rng_key = jax.random.split(master_rng_key)\n",
        "\n",
        "        parent_pool_for_offspring = ranked_population[:num_elites] if num_elites > 0 else ranked_population\n",
        "        if not parent_pool_for_offspring and population_size > 0: # If no elites and pop_size > 0, use whole pop as parents\n",
        "             parent_pool_for_offspring = ranked_population\n",
        "\n",
        "        # Ensure there are parents to select from if we need to generate offspring\n",
        "        if num_offspring_to_generate > 0 and not parent_pool_for_offspring :\n",
        "            print(\"Warning: No parents available to generate offspring. Skipping offspring generation for this gen.\")\n",
        "            num_offspring_to_generate = 0\n",
        "\n",
        "        for i in range(num_offspring_to_generate):\n",
        "            if current_total_timesteps >= total_training_budget:\n",
        "                print(\"Budget reached during offspring generation.\")\n",
        "                break\n",
        "\n",
        "            key_offspring_loop_master, offspring_rng_key = jax.random.split(key_offspring_loop_master)\n",
        "\n",
        "            _, child, did_finetune = evolve_offspring(\n",
        "                parent_pool_for_offspring, # Pass the pool from which parents can be selected\n",
        "                min(len(parent_pool_for_offspring), num_elites if num_elites > 0 else 2), # Effective number of elites for selection logic\n",
        "                mutation_rate, mutation_scale, offspring_rng_key,\n",
        "                env_name, env_cfg, ppo_cfg_finetune, finetune_timesteps_per_offspring\n",
        "            )\n",
        "            offspring.append(child)\n",
        "\n",
        "            # Only add to budget if PPO fine-tuning occurred\n",
        "            if did_finetune:\n",
        "                current_total_timesteps += finetune_timesteps_per_offspring\n",
        "\n",
        "        # Form New Population\n",
        "        population = elites + offspring\n",
        "        idx = 0\n",
        "        while len(population) < population_size: # Pad if budget cut short offspring gen\n",
        "            if elites:\n",
        "                 population.append(copy_params(elites[idx % len(elites)]))\n",
        "            elif ranked_population :\n",
        "                 population.append(copy_params(ranked_population[0][1]))\n",
        "            else: # Should not be reached if initial pop > 0\n",
        "                 population.append(copy_params(base_params))\n",
        "            idx +=1\n",
        "            if idx > population_size * 2: break # Safety break\n",
        "\n",
        "    # Finish EPO run\n",
        "    print(f\"[EPO] Finished. Total PPO steps used: {current_total_timesteps}. Best fitness: {best_fitness}. Log: {csv_log_path}\")\n",
        "    if enable_wandb:\n",
        "        try:\n",
        "            video_local_path = f\"epo_best_agent_{env_name}_seed{seed}.mp4\"\n",
        "            video_path_drive = record_video(best_agent_params, inference_fn_factory, env_name, env_cfg,\n",
        "                                          path=video_local_path, seed=seed + 3000)\n",
        "            wandb.log({\"final_best_agent_video\": wandb.Video(video_path_drive, caption=f\"EPO Best {env_name} Seed {seed}\")})\n",
        "            base_video_name = os.path.basename(video_path_drive)\n",
        "            dest_path = os.path.join(DRIVE_PATH, base_video_name)\n",
        "            if os.path.abspath(video_path_drive) != os.path.abspath(dest_path):\n",
        "                if os.path.exists(video_path_drive): os.rename(video_path_drive, dest_path)\n",
        "        except Exception as e: print(f\"Wandb video logging failed for EPO best: {e}\")\n",
        "        finally: wandb.finish()\n",
        "\n",
        "    return best_agent_params, all_max_fitness_over_generations, csv_log_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8fL_d6UO51g_MODIFIED"
      },
      "source": [
        "# Experiment Setup & Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gsw-UXQcPSfn_MODIFIED"
      },
      "outputs": [],
      "source": [
        "# Multi-seed EPO Runner\n",
        "def run_epo_across_seeds(env_name: str,\n",
        "                           total_budget: int,\n",
        "                           env_cfg: config_dict.ConfigDict,\n",
        "                           ppo_cfg_pretrain: config_dict.ConfigDict,\n",
        "                           ppo_cfg_finetune: config_dict.ConfigDict,\n",
        "                           seeds: List[int],\n",
        "                           epo_specific_kwargs: dict,\n",
        "                           enable_wandb_runs: bool = False):\n",
        "    all_seeds_final_rewards = []\n",
        "    summary_csv_filename = f\"epo_summary_rewards_{env_name}_allseeds.csv\"\n",
        "    csv_summary_path = os.path.join(DRIVE_PATH, summary_csv_filename)\n",
        "\n",
        "    with open(csv_summary_path, \"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Seed\", \"Final_Best_Fitness\"])\n",
        "        for s_val in seeds:\n",
        "            print(f\"\\n=== Running EPO on {env_name} (Seed={s_val}) ===\")\n",
        "            _, rewards_history, individual_log_path = run_epo_brax(\n",
        "                env_name=env_name, total_training_budget=total_budget,\n",
        "                env_cfg=env_cfg, ppo_cfg_pretrain=ppo_cfg_pretrain,\n",
        "                ppo_cfg_finetune=ppo_cfg_finetune, seed=s_val,\n",
        "                enable_wandb=enable_wandb_runs, **epo_specific_kwargs)\n",
        "            final_best_fitness = rewards_history[-1] if rewards_history else np.nan\n",
        "            all_seeds_final_rewards.append(final_best_fitness)\n",
        "            writer.writerow([s_val, final_best_fitness])\n",
        "            print(f\"EPO Seed {s_val} finished. Final best fitness: {final_best_fitness}. Gen log: {individual_log_path}\")\n",
        "\n",
        "    print(f\"\\nEPO runs complete for all seeds. Summary: {csv_summary_path}\")\n",
        "    return np.array(all_seeds_final_rewards)\n",
        "\n",
        "# Multi-seed PPO Baseline Runner\n",
        "def run_ppo_baseline_across_seeds(env_name: str,\n",
        "                                  total_timesteps_per_run: int,\n",
        "                                  env_cfg: config_dict.ConfigDict,\n",
        "                                  ppo_cfg: config_dict.ConfigDict,\n",
        "                                  seeds: List[int],\n",
        "                                  enable_wandb_runs: bool = False):\n",
        "    all_seeds_final_rewards = []\n",
        "    summary_csv_filename = f\"ppo_baseline_summary_rewards_{env_name}_allseeds.csv\"\n",
        "    csv_summary_path = os.path.join(DRIVE_PATH, summary_csv_filename)\n",
        "\n",
        "    with open(csv_summary_path, \"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Seed\", \"Final_Evaluation_Reward\"])\n",
        "        for s_val in seeds:\n",
        "            print(f\"\\n=== Running PPO Baseline on {env_name} (Seed={s_val}) ===\")\n",
        "            _, final_reward = train_ppo_baseline(\n",
        "                env_name=env_name, total_timesteps=total_timesteps_per_run,\n",
        "                env_cfg=env_cfg, ppo_cfg=ppo_cfg, seed=s_val,\n",
        "                enable_wandb=enable_wandb_runs)\n",
        "            all_seeds_final_rewards.append(final_reward)\n",
        "            writer.writerow([s_val, final_reward])\n",
        "            print(f\"PPO Baseline Seed {s_val} finished. Final eval reward: {final_reward}\")\n",
        "\n",
        "    print(f\"\\nPPO Baseline runs complete for all seeds. Summary: {csv_summary_path}\")\n",
        "    return np.array(all_seeds_final_rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w1lDrtjSHYr_MODIFIED"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "def summarize_results(results: np.ndarray) -> Tuple[float, float, Tuple[float, float]]:\n",
        "    mean = np.mean(results)\n",
        "    std = np.std(results)\n",
        "    if len(results) < 2:\n",
        "        ci = (np.nan, np.nan)\n",
        "    else:\n",
        "        ci = st.t.interval(0.95, len(results)-1, loc=mean, scale=st.sem(results))\n",
        "    return mean, std, ci\n",
        "\n",
        "def compare_results(results1: np.ndarray, results2: np.ndarray) -> Tuple[float, float]:\n",
        "    if len(results1) != len(results2) or len(results1) < 2:\n",
        "        print(\"Cannot perform paired t-test: arrays must be same length >= 2.\")\n",
        "        return np.nan, np.nan\n",
        "    t_stat, p_val = st.ttest_rel(results1, results2)\n",
        "    return t_stat, p_val\n",
        "\n",
        "def summarize_and_plot(all_epo_rewards: np.ndarray, all_ppo_rewards: np.ndarray, experiment_title:str = \"Performance Comparison\"):\n",
        "    epo_mean, epo_std, epo_ci = summarize_results(all_epo_rewards)\n",
        "    ppo_mean, ppo_std, ppo_ci = summarize_results(all_ppo_rewards)\n",
        "\n",
        "    print(\"\\n--- EPO Results ---\")\n",
        "    print(f\"Mean: {epo_mean:.2f}, Std: {epo_std:.2f}, 95% CI: ({epo_ci[0]:.2f}, {epo_ci[1]:.2f})\")\n",
        "    print(f\"Raw EPO rewards: {all_epo_rewards}\")\n",
        "\n",
        "    print(\"\\n--- PPO Baseline Results ---\")\n",
        "    print(f\"Mean: {ppo_mean:.2f}, Std: {ppo_std:.2f}, 95% CI: ({ppo_ci[0]:.2f}, {ppo_ci[1]:.2f})\")\n",
        "    print(f\"Raw PPO rewards: {all_ppo_rewards}\")\n",
        "\n",
        "    t_stat, p_val = compare_results(all_epo_rewards, all_ppo_rewards)\n",
        "    print(\"\\n--- Paired t-test (EPO vs PPO) ---\")\n",
        "    if not (np.isnan(t_stat) or np.isnan(p_val)):\n",
        "        print(f\"t-statistic: {t_stat:.3f}, p-value: {p_val:.4f}\")\n",
        "        significance_level = 0.05\n",
        "        if p_val < significance_level:\n",
        "            print(f\"The difference is statistically significant (p < {significance_level}).\")\n",
        "        else:\n",
        "            print(f\"The difference is not statistically significant (p >= {significance_level}).\")\n",
        "    else:\n",
        "        print(\"Could not compute t-test.\")\n",
        "\n",
        "    try:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.boxplot([all_epo_rewards[~np.isnan(all_epo_rewards)], all_ppo_rewards[~np.isnan(all_ppo_rewards)]], labels=[\"EPO\", \"PPO Baseline\"])\n",
        "        plt.ylabel(\"Final Reward/Fitness\")\n",
        "        plt.title(f\"{experiment_title} across Seeds\")\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        # display(plt.gcf()) # display is handled by run_epo_brax / train_ppo for progress plots\n",
        "        plt.show() # Use plt.show() for final summary plot\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Boxplot error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrS40EuyAG-5",
        "outputId": "ad3fae87-c62c-4194-b0cd-f1ea7ec3ebec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Experiment: Go1Footstand ===\n",
            "Using default env_cfg from: cell RYriZOAxzEk_Config\n",
            "Using PPO params for pretrain/baseline from: cell RYriZOAxzEk_Config\n",
            "PPO params for EPO finetuning: {'action_repeat': 1, 'batch_size': 256, 'discounting': 0.97, 'entropy_cost': 0.01, 'episode_length': 500, 'learning_rate': 0.00015, 'max_grad_norm': 1.0, 'network_factory': {'policy_hidden_layer_sizes': (512, 256, 128), 'policy_obs_key': 'state', 'value_hidden_layer_sizes': (512, 256, 128), 'value_obs_key': 'privileged_state'}, 'normalize_observations': True, 'num_envs': 8192, 'num_evals': 5, 'num_minibatches': 32, 'num_timesteps': 100000000, 'num_updates_per_batch': 4, 'reward_scaling': 1.0, 'unroll_length': 20}\n",
            "EPO Specific Kwargs: {'population_size': 8, 'num_elites': 3, 'pretrain_timesteps': 5000000, 'finetune_timesteps_per_offspring': 500, 'mutation_rate': 0.3, 'mutation_scale': 0.05}\n"
          ]
        }
      ],
      "source": [
        "# Main experiment execution cell for Go1Handstand\n",
        "ENABLE_WANDB_LOGGING = False # Set to True to log to Weights & Biases\n",
        "\n",
        "print(f\"=== Experiment: {ENV_NAME_HANDSTAND} ===\")\n",
        "print(f\"Using default env_cfg from: cell RYriZOAxzEk_Config\")\n",
        "print(f\"Using PPO params for pretrain/baseline from: cell RYriZOAxzEk_Config\")\n",
        "\n",
        "# SEEDS_LIST = [SEED_GLOBAL, SEED_GLOBAL + 1, SEED_GLOBAL + 2]\n",
        "SEEDS_LIST = [SEED_GLOBAL] # For a quick single seed test\n",
        "\n",
        "# PPO parameters for EPO's finetuning steps\n",
        "ppo_params_handstand_finetune_epo = config_dict.ConfigDict(PPO_PARAMS_HANDSTAND_DEFAULT)\n",
        "ppo_params_handstand_finetune_epo.learning_rate = PPO_PARAMS_HANDSTAND_DEFAULT.learning_rate * 0.5\n",
        "ppo_params_handstand_finetune_epo.num_minibatches = PPO_PARAMS_HANDSTAND_DEFAULT.num_minibatches\n",
        "# Ensure episode_length for finetuning makes sense with finetune_timesteps_per_offspring\n",
        "# The ppo_cfg.episode_length is used by the wrapper to decide when to auto-reset.\n",
        "# It should typically be <= FINETUNE_TIMESTEPS_EPO if an offspring is trained for that many steps.\n",
        "ppo_params_handstand_finetune_epo.episode_length = PPO_PARAMS_HANDSTAND_DEFAULT.episode_length\n",
        "\n",
        "print(f\"PPO params for EPO finetuning: {ppo_params_handstand_finetune_epo.to_dict()}\")\n",
        "\n",
        "# EPO hyperparameters are defined here\n",
        "epo_kwargs_handstand = {\n",
        "    \"population_size\": 8,\n",
        "    \"num_elites\": 3,\n",
        "    # Pretrain for a fraction of the total budget or a fixed reasonable amount\n",
        "    \"pretrain_timesteps\": 5_000_000,\n",
        "    \"finetune_timesteps_per_offspring\": FINETUNE_TIMESTEPS_EPO,\n",
        "    \"mutation_rate\": 0.3,\n",
        "    \"mutation_scale\": 0.05\n",
        "}\n",
        "print(f\"EPO Specific Kwargs: {epo_kwargs_handstand}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_86PgOe3Wa0q_MODIFIED_TITLE"
      },
      "source": [
        "# Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "BWoUR02iTqOC_MODIFIED",
        "outputId": "9901c64b-3d63-43b1-860c-a0eb8aef7f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timesteps: 5242880, Reward: 3.382915496826172\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to JIT: 0:02:19.363753\n",
            "Time to Train: 0:01:44.469464\n",
            "PPO pre-train steps used: 5000000/30000000) ---\n",
            "Initial pre-trained agent fitness: 5.987700462341309\n",
            "--- EPO Gen 1 ---\n",
            "Evaluating population 1...\n"
          ]
        }
      ],
      "source": [
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        # Run EPO\n",
        "print(f\"\\n>>> STARTING EPO RUNS FOR {ENV_NAME_HANDSTAND} <<<\")\n",
        "epo_results_handstand = run_epo_across_seeds(\n",
        "    env_name=ENV_NAME_HANDSTAND,\n",
        "    total_budget=TOTAL_TIMESTEPS_EXPERIMENT,\n",
        "    env_cfg=ENV_CFG_HANDSTAND_DEFAULT,\n",
        "    ppo_cfg_pretrain=PPO_PARAMS_HANDSTAND_DEFAULT,\n",
        "    ppo_cfg_finetune=ppo_params_handstand_finetune_epo,\n",
        "    seeds=SEEDS_LIST,\n",
        "    epo_specific_kwargs=epo_kwargs_handstand,\n",
        "    enable_wandb_runs=ENABLE_WANDB_LOGGING\n",
        ")\n",
        "\n",
        "# Run PPO Baseline\n",
        "print(f\"\\n>>> STARTING PPO BASELINE RUNS FOR {ENV_NAME_HANDSTAND} <<<\")\n",
        "ppo_results_handstand = run_ppo_baseline_across_seeds(\n",
        "    env_name=ENV_NAME_HANDSTAND,\n",
        "    total_timesteps_per_run=TOTAL_TIMESTEPS_EXPERIMENT,\n",
        "    env_cfg=ENV_CFG_HANDSTAND_DEFAULT,\n",
        "    ppo_cfg=PPO_PARAMS_HANDSTAND_DEFAULT,\n",
        "    seeds=SEEDS_LIST,\n",
        "    enable_wandb_runs=ENABLE_WANDB_LOGGING\n",
        ")\n",
        "\n",
        "print(f\"\\n=== FINAL RESULTS SUMMARY FOR {ENV_NAME_HANDSTAND} ===\")\n",
        "summarize_and_plot(epo_results_handstand, ppo_results_handstand, experiment_title=f\"{ENV_NAME_HANDSTAND} Performance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN9G88o0sumz"
      },
      "outputs": [],
      "source": [
        "# 1) plot different p values (1M, 25M)\n",
        "# 2) different p/f pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM7WquP6MI24"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Assuming the experiment has been run and the CSV log file is available.\n",
        "# Construct the path to the CSV log file.\n",
        "# These variables are defined in your notebook:\n",
        "#. DRIVE_PATH = \"/content/EPO_results/\" (defined in cell iBMsUa10Sl4W)\n",
        "# ENV_NAME_HANDSTAND = 'Go1Handstand' (defined in cell RYriZOAxzEk_Config)\n",
        "# SEED_GLOBAL = 42 (defined in cell RYriZOAxzEk_Config)\n",
        "# SEEDS_LIST uses SEED_GLOBAL. We'll assume the first seed for a single plot.\n",
        "\n",
        "# Check if variables are in the global scope, otherwise use default values from notebook\n",
        "try:\n",
        "    drive_path = DRIVE_PATH\n",
        "except NameError:\n",
        "    drive_path = \"/content/EPO_results/\"\n",
        "    print(f\"Warning: DRIVE_PATH not found, using default: {drive_path}\")\n",
        "\n",
        "try:\n",
        "    env_name = ENV_NAME_HANDSTAND\n",
        "except NameError:\n",
        "    env_name = 'Go1Handstand'\n",
        "    print(f\"Warning: ENV_NAME_HANDSTAND not found, using default: {env_name}\")\n",
        "\n",
        "try:\n",
        "    # Assuming you want to plot for the first seed in SEEDS_LIST\n",
        "    seed = SEEDS_LIST[0]\n",
        "except NameError:\n",
        "    try:\n",
        "        seed = SEED_GLOBAL\n",
        "    except NameError:\n",
        "        seed = 42 # Default if SEED_GLOBAL is also not found\n",
        "    print(f\"Warning: SEEDS_LIST or SEED_GLOBAL not found, using default seed: {seed}\")\n",
        "\n",
        "\n",
        "csv_log_filename = f\"epo_gen_log_{env_name}_seed{seed}.csv\"\n",
        "csv_log_path = os.path.join(drive_path, csv_log_filename)\n",
        "\n",
        "print(f\"Attempting to read log file from: {csv_log_path}\")\n",
        "\n",
        "try:\n",
        "    # Read the CSV file\n",
        "    log_df = pd.read_csv(csv_log_path)\n",
        "\n",
        "    # Check if the necessary columns exist\n",
        "    if \"TotalEnvSteps\" not in log_df.columns or \"MaxFitness\" not in log_df.columns:\n",
        "        print(f\"Error: The CSV file {csv_log_path} does not contain the required columns 'TotalEnvSteps' or 'MaxFitness'.\")\n",
        "        print(f\"Available columns: {log_df.columns.tolist()}\")\n",
        "    else:\n",
        "        # Create the plot\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        plt.plot(log_df[\"TotalEnvSteps\"], log_df[\"MaxFitness\"], marker='o', linestyle='-')\n",
        "\n",
        "        # Add labels and title\n",
        "        plt.xlabel(\"TOTAL TIMESTEPS (TotalEnvSteps)\")\n",
        "        plt.ylabel(\"Training Reward (MaxFitness per Generation)\")\n",
        "        plt.title(f\"EPO Training Reward over Time for {env_name} (Seed {seed})\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The log file was not found at {csv_log_path}.\")\n",
        "    print(\"Please ensure that the EPO experiment has been run and the file was saved correctly.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while trying to plot the results: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2RNqt5uJopk",
        "outputId": "0f97dbb3-fb1d-443b-d2d4-7260981aa947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPO Results: [15.859]\n",
            "PPO Baseline Results: [13.491]\n"
          ]
        }
      ],
      "source": [
        "# print results\n",
        "print(f\"EPO Results: {epo_results_handstand}\")\n",
        "print(f\"PPO Baseline Results: {ppo_results_handstand}\")\n",
        "\n",
        "# # print all_ppo_results and all_epo_results\n",
        "# print(f\"All EPO Results: {all_epo_results}\")\n",
        "# print(f\"All PPO Baseline Results: {all_ppo_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEvnGWWZDsHI_OptionalRender"
      },
      "outputs": [],
      "source": [
        "# Optional: Code for rendering rollouts of the best PPO and EPO agents\n",
        "print(\"\\nNotebook execution finished. Check Drive path for results and videos if generated.\")\n",
        "print(f\"Drive Path: {DRIVE_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}